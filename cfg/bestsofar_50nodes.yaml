batch_size: 64
n_epochs: 20
reward_scale: 1.0
lr: 0.0016134816080499328
decay: 0.0008404361781997002
optimizer: Adam
baseline_mode: neural
# eval_n_routes: [1, 5, 10, 15, 20]
eval_n_routes: 10
discount_rate: null
entropy_weight: 0.0

eval:
  min_route_len: 5
  max_route_len: 20

dataset:
  type: pickle
  kwargs:
    path: datasets/mixed_50
    space_scale: 0.6
    demand_scale: 0.2

defaults:
  - _self_
  - experiment: standard
  - model: bestsofar_feb2023
